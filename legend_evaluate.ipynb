{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641a3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_26016\\1204594300.py:27: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  hyde_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Literal, Annotated\n",
    "from datetime import date\n",
    "import json \n",
    "\n",
    "# tools.py 파일에서 TOOLS를 임포트\n",
    "from tools import TOOLS\n",
    "\n",
    "# =================== Embedding & VectorStore ===================\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=\"rag_chatbot\",\n",
    "    persist_directory=\"vector_store/chroma/rag_chatbot\"\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# =================== Prompt Chains ===================\n",
    "hyde_chain = LLMChain(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4.1\", streaming=True),\n",
    "    prompt=ChatPromptTemplate.from_template(\"\"\"#Instruction:\n",
    "다음 질문에 대해서 완전하고 상세한 답변으로 실제 사실에 기반해서 작성해주세요.\n",
    "질문과 관련된 내용만으로 작성합니다.\n",
    "답변과 직접적인 연관성이 없는 내용은 답변에 포함시키지 않습니다.\n",
    "\n",
    "# 질문:\n",
    "{query}\n",
    "\"\"\")\n",
    ")\n",
    "\n",
    "llm_check_chain = LLMChain(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4.1\", streaming=True),\n",
    "    prompt=ChatPromptTemplate.from_template(\"\"\"\n",
    "다음 Context는 사용자의 질문에 대해 충분한 정보를 제공하고 있는가?\n",
    "질문: {query}\n",
    "Context: {context}\n",
    "\n",
    "위 Context만으로 정확하고 신뢰할 수 있는 답변이 가능한 경우 'Y',\n",
    "불충분하다면 'N',\n",
    "관련 없는 경우 'llm_message'로 답해주세요.\n",
    "\n",
    "정확하게 하나의 문자만 출력하세요.\n",
    "\"\"\")\n",
    ")\n",
    "\n",
    "# LLM이 도구 결과 요약 및 사용자 정보 기반 답변 생성을 위한 새로운 체인\n",
    "response_synthesis_llm = ChatOpenAI(model_name=\"gpt-4.1\", streaming=True)\n",
    "response_synthesis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"\n",
    "    당신은 사용자에게 친절하고 정확하게 답변하는 AI 어시스턴트입니다.\n",
    "    오늘 날짜는 {date.today().strftime('%Y년 %m월 %d일')}입니다.\n",
    "    사용자의 질문과, 제공된 정보 또는 대화 기록을 바탕으로 답변을 완성하세요.\n",
    "    사용자 이름이 주어졌다면 답변에 친근하게 활용하세요.\n",
    "    \n",
    "    # 사용자 정보:\n",
    "    이름: {{user_name}}\n",
    "    \n",
    "    # 대화 기록:\n",
    "    {{chat_history}}\n",
    "    \n",
    "    # 제공된 정보 (도구 실행 결과 또는 RAG 컨텍스트):\n",
    "    {{context}}\n",
    "    \n",
    "    # 답변:\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "response_synthesis_chain = response_synthesis_prompt | response_synthesis_llm\n",
    "\n",
    "\n",
    "# 엔티티 추출을 위한 LLM 체인\n",
    "entity_extraction_llm = ChatOpenAI(model_name=\"gpt-4.1-mini\")\n",
    "entity_extraction_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "주어진 대화에서 사용자의 이름을 정확히 추출해주세요. 이름만 추출하며, \"이름:\", \"내 이름은\"과 같은 접두사는 포함하지 마세요.\n",
    "이름을 찾을 수 없다면 \"None\"이라고 답변하세요.\n",
    "\n",
    "예시:\n",
    "대화: 안녕 나 강감찬이야\n",
    "이름: 강감찬\n",
    "\n",
    "대화: 안녕하세요\n",
    "이름: None\n",
    "\n",
    "대화: 내 이름은 김철수야\n",
    "이름: 김철수\n",
    "\n",
    "대화: {dialogue}\n",
    "이름:\n",
    "\"\"\")\n",
    "entity_extraction_chain = entity_extraction_prompt | entity_extraction_llm\n",
    "\n",
    "# =================== GraphState ===================\n",
    "class GraphState(BaseModel):\n",
    "    messages: Annotated[List, add_messages]\n",
    "    query: str = \"\"\n",
    "    hyde_answer: str = \"\"\n",
    "    context_docs: List = []\n",
    "    context_str: str = \"\"\n",
    "    tool_result: str = \"\"\n",
    "    route: Literal[\"use_rag\", \"use_tool\", \"llm_message\", \"tool_call\", \"synthesize_response\"] = \"use_rag\" \n",
    "    final_answer: str = \"\"\n",
    "    source: str = \"\"\n",
    "    user_name: str = \"\" \n",
    "\n",
    "# =================== Helper Functions ===================\n",
    "def format_docs(docs: list) -> str:\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def run_hyde(state: GraphState):\n",
    "    latest_message = state.messages[-1].content\n",
    "    \n",
    "    hyde_result = hyde_chain.invoke({\"query\": latest_message})\n",
    "    \n",
    "    if isinstance(hyde_result, dict):\n",
    "        hyde_answer = hyde_result.get(\"text\", hyde_result.get(\"answer\", str(hyde_result)))\n",
    "    else:\n",
    "        hyde_answer = str(hyde_result)\n",
    "            \n",
    "    print(f\"DEBUG: Hyde Answer: '{hyde_answer}'\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": latest_message, # 현재 턴의 질문을 query로 설정\n",
    "        \"hyde_answer\": hyde_answer,\n",
    "        \"messages\": state.messages + [AIMessage(content=hyde_answer)],\n",
    "    }\n",
    "\n",
    "def run_retriever(state: GraphState):\n",
    "    docs = retriever.invoke(state.hyde_answer)\n",
    "    \n",
    "    if not docs:\n",
    "        print(\"DEBUG: No documents found by retriever. Routing to tool or fallback.\")\n",
    "        return {\"context_docs\": [], \"context_str\": \"\", \"route\": \"tool_call\"} \n",
    "        \n",
    "    context_str = format_docs(docs)\n",
    "    print(f\"DEBUG: Retrieved Context: '{context_str[:200]}...'\")\n",
    "    return {\"context_docs\": docs, \"context_str\": context_str, \"route\": \"synthesize_response\"}\n",
    "\n",
    "def route_decision(state: GraphState):\n",
    "    llm_check_result = llm_check_chain.invoke({\"query\": state.query, \"context\": state.context_str})\n",
    "    \n",
    "    decision_raw = \"\"\n",
    "    if isinstance(llm_check_result, dict):\n",
    "        decision_raw = llm_check_result.get(\"text\", llm_check_result.get(\"answer\", str(llm_check_result)))\n",
    "    else:\n",
    "        decision_raw = str(llm_check_result)\n",
    "    \n",
    "    decision = decision_raw.strip().lower()\n",
    "\n",
    "    print(f\"DEBUG: LLM Check Decision Raw: '{decision_raw}'\")\n",
    "    print(f\"DEBUG: LLM Check Decision Processed: '{decision}'\")\n",
    "\n",
    "    if decision == \"y\":\n",
    "        return {\"route\": \"use_rag\"}\n",
    "    elif decision == \"n\":\n",
    "        return {\"route\": \"tool_call\"}\n",
    "    else:\n",
    "        # LLM이 직접 답변해야 하는 경우에도 synthesize_response를 거치도록 변경\n",
    "        # query와 messages를 바탕으로 답변을 생성하게 함\n",
    "        return {\"route\": \"synthesize_response\"} \n",
    "\n",
    "# =================== Tool Node Functions ===================\n",
    "tool_calling_llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", streaming=True).bind_tools(TOOLS)\n",
    "\n",
    "def call_tool_llm(state: GraphState):\n",
    "    print(f\"DEBUG: Calling tool_calling_llm with query: {state.query}\")\n",
    "    response = tool_calling_llm.invoke(state.query)\n",
    "    \n",
    "    if response.tool_calls:\n",
    "        print(f\"DEBUG: Tool Call detected: {response.tool_calls}\")\n",
    "        return {\"messages\": state.messages + [response]}\n",
    "    else:\n",
    "        print(f\"DEBUG: No tool call, LLM responded directly: {response.content}\")\n",
    "        # LLM이 직접 답변한 경우에도 synthesize_response로 넘겨서 최종 답변 포맷팅\n",
    "        return {\n",
    "            \"tool_result\": response.content, # LLM의 직접 응답을 tool_result에 저장하여 context로 활용\n",
    "            \"messages\": state.messages + [response],\n",
    "            \"source\": \"llm_tool_fallback\",\n",
    "            \"route\": \"synthesize_response\" # synthesize_response로 라우팅\n",
    "        }\n",
    "\n",
    "def process_tool_result(state: GraphState):\n",
    "    tool_message = None\n",
    "    for msg in reversed(state.messages):\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            tool_message = msg\n",
    "            break\n",
    "\n",
    "    if tool_message:\n",
    "        tool_output_raw = tool_message.content\n",
    "        tool_name = tool_message.name\n",
    "        tool_id = tool_message.tool_call_id\n",
    "\n",
    "        print(f\"DEBUG: Tool execution result for tool '{tool_name}' (ID: {tool_id}): '{tool_output_raw[:200]}...'\")\n",
    "        \n",
    "        processed_tool_output = \"\"\n",
    "        source = tool_name \n",
    "\n",
    "        # search_web 도구의 출력 처리\n",
    "        if tool_name == \"search_web\":\n",
    "            try:\n",
    "                parsed_output = json.loads(tool_output_raw)\n",
    "                if isinstance(parsed_output, dict) and \"results\" in parsed_output:\n",
    "                    search_results_list = parsed_output[\"results\"]\n",
    "                    if search_results_list:\n",
    "                        formatted_results = []\n",
    "                        for res in search_results_list:\n",
    "                            content_snippet = res.get(\"content\", \"내용 없음\")\n",
    "                            if content_snippet:\n",
    "                                content_snippet = content_snippet[:500] + \"...\" if len(content_snippet) > 500 else content_snippet\n",
    "                            formatted_results.append(\n",
    "                                f\"**제목:** {res.get('title', '제목 없음')}\\n\"\n",
    "                                f\"**URL:** {res.get('url', 'URL 없음')}\\n\"\n",
    "                                f\"**내용:** {content_snippet}\\n\"\n",
    "                                f\"---\"\n",
    "                            )\n",
    "                        processed_tool_output = \"\\n\\n\".join(formatted_results)\n",
    "                    else:\n",
    "                        processed_tool_output = \"인터넷 검색 결과가 없습니다.\"\n",
    "                else:\n",
    "                    processed_tool_output = \"인터넷 검색 결과 형식 오류.\"\n",
    "            except json.JSONDecodeError as e:\n",
    "                processed_tool_output = f\"인터넷 검색 결과 JSON 파싱 오류: {e}\"\n",
    "                print(f\"ERROR: Search web result JSON parsing failed: {e}\")\n",
    "            except Exception as e:\n",
    "                processed_tool_output = f\"인터넷 검색 결과 처리 중 오류 발생: {e}\"\n",
    "                print(f\"ERROR: Search web result processing failed: {e}\")\n",
    "        else:\n",
    "            processed_tool_output = tool_output_raw # LLM이 요약하도록 원본 전달\n",
    "\n",
    "        if not processed_tool_output or \\\n",
    "           \"접근할 수 없습니다\" in processed_tool_output or \\\n",
    "           \"검색결과가 없습니다\" in processed_tool_output:\n",
    "            \n",
    "            return {\n",
    "                \"final_answer\": \"죄송합니다. 도구에서 관련 정보를 찾지 못했습니다.\",\n",
    "                \"source\": \"llm\",\n",
    "                \"tool_result\": tool_output_raw \n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"tool_result\": processed_tool_output,\n",
    "            \"source\": source,\n",
    "            \"route\": \"synthesize_response\"\n",
    "        }\n",
    "    else:\n",
    "        print(\"DEBUG: process_tool_result called but no recent ToolMessage found.\")\n",
    "        return {\"final_answer\": \"도구 실행 결과를 처리할 수 없습니다.\", \"source\": \"llm\"}\n",
    "\n",
    "\n",
    "def synthesize_response(state: GraphState):\n",
    "    print(\"DEBUG: Entering synthesize_response node.\")\n",
    "    context_to_synthesize = state.context_str \n",
    "    if state.tool_result: # tool_result가 있다면 (도구 호출 또는 LLM 직접 응답)\n",
    "        context_to_synthesize = state.tool_result\n",
    "        print(f\"DEBUG: Synthesizing with Tool Result (or direct LLM response): {context_to_synthesize[:200]}...\")\n",
    "    elif not context_to_synthesize: # RAG 컨텍스트도 없고 tool_result도 없는 경우\n",
    "        print(\"DEBUG: No context or tool result to synthesize with.\")\n",
    "        # 이 경우 LLM이 chat_history만으로 답변 시도\n",
    "        context_to_synthesize = \"\" \n",
    "\n",
    "    try:\n",
    "        # chat_history를 프롬프트에 포함하여 LLM이 대화 흐름을 이해하도록 함\n",
    "        # LangChain의 messages 리스트를 그대로 전달\n",
    "        final_answer_message = response_synthesis_chain.invoke({\n",
    "            \"query\": state.query,\n",
    "            \"context\": context_to_synthesize,\n",
    "            \"user_name\": state.user_name,\n",
    "            \"chat_history\": state.messages[:-1] # 마지막 사용자 메시지 제외 (현재 쿼리이므로)\n",
    "        })\n",
    "        final_answer_text = final_answer_message.content\n",
    "        print(f\"DEBUG: Synthesized Final Answer: '{final_answer_text}'\")\n",
    "        \n",
    "        # LLM_tool_fallback이 synthesize_response로 넘어왔을 때 source를 llm으로 변경\n",
    "        source_for_output = state.source\n",
    "        if source_for_output == \"llm_tool_fallback\":\n",
    "            source_for_output = \"llm\"\n",
    "\n",
    "        return {\n",
    "            \"final_answer\": final_answer_text,\n",
    "            \"source\": source_for_output\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Response synthesis failed: {e}\")\n",
    "        return {\"final_answer\": \"죄송합니다. 답변을 생성하는 데 실패했습니다.\", \"source\": \"llm\"}\n",
    "\n",
    "\n",
    "def extract_user_name(state: GraphState):\n",
    "    last_human_message_content = \"\"\n",
    "    for msg in reversed(state.messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            last_human_message_content = msg.content\n",
    "            break\n",
    "\n",
    "    if last_human_message_content:\n",
    "        name_extraction_result = entity_extraction_chain.invoke({\"dialogue\": last_human_message_content})\n",
    "        extracted_name_raw = name_extraction_result.content.strip()\n",
    "        \n",
    "        # '이름:' 접두사 제거\n",
    "        if extracted_name_raw.startswith(\"이름:\"):\n",
    "            extracted_name = extracted_name_raw[len(\"이름:\"):].strip()\n",
    "        else:\n",
    "            extracted_name = extracted_name_raw\n",
    "        \n",
    "        print(f\"DEBUG: Extracted name raw: '{extracted_name_raw}'\")\n",
    "        print(f\"DEBUG: Extracted name processed: '{extracted_name}'\")\n",
    "        \n",
    "        if extracted_name.lower() != \"none\" and extracted_name:\n",
    "            print(f\"DEBUG: User name extracted: '{extracted_name}'\")\n",
    "            return {\"user_name\": extracted_name}\n",
    "    \n",
    "    print(\"DEBUG: No user name extracted or 'None'.\")\n",
    "    return {\"user_name\": state.user_name}\n",
    "\n",
    "def fallback_node(state: GraphState):\n",
    "    final_answer = state.final_answer or \"죄송합니다. 관련 정보를 찾지 못했습니다.\"\n",
    "    print(f\"DEBUG: Fallback Answer: '{final_answer}'\")\n",
    "    \n",
    "    # fallback 시에도 synthesize_response를 거치도록 변경\n",
    "    # fallback은 일반적으로 최종 답변을 내지 않고, LLM에게 최종 답변을 맡기는 역할\n",
    "    return {\"final_answer\": final_answer, \"source\": \"llm\"} # 직접 답변하지 않고, synthesize_response로 넘어가야 함\n",
    "\n",
    "# =================== Graph Setup ===================\n",
    "checkpointer = MemorySaver()\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"extract_name\", extract_user_name) \n",
    "graph.add_node(\"hyde\", run_hyde)\n",
    "graph.add_node(\"retrieve\", run_retriever)\n",
    "graph.add_node(\"check_route\", route_decision)\n",
    "graph.add_node(\"call_tool_llm\", call_tool_llm)\n",
    "graph.add_node(\"process_tool_result\", process_tool_result)\n",
    "from langgraph.prebuilt import ToolNode\n",
    "tool_node = ToolNode(TOOLS)\n",
    "graph.add_node(\"tool_runner\", tool_node)\n",
    "graph.add_node(\"synthesize_response\", synthesize_response)\n",
    "graph.add_node(\"fallback\", fallback_node) # fallback 노드는 synthesize_response로 연결\n",
    "\n",
    "graph.set_entry_point(\"extract_name\")\n",
    "\n",
    "graph.add_edge(\"extract_name\", \"hyde\")\n",
    "\n",
    "graph.add_edge(\"hyde\", \"check_route\")\n",
    "\n",
    "graph.add_conditional_edges(\"check_route\", lambda state: state.route, {\n",
    "    \"use_rag\": \"retrieve\",\n",
    "    \"tool_call\": \"call_tool_llm\",\n",
    "    \"llm_message\": \"synthesize_response\" # llm_message인 경우 synthesize_response로 바로 이동\n",
    "})\n",
    "\n",
    "graph.add_edge(\"retrieve\", \"synthesize_response\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"call_tool_llm\",\n",
    "    # LLM이 도구 호출을 하지 않고 직접 응답한 경우 바로 synthesize_response로 이동\n",
    "    lambda state: \"tool_runner\" if hasattr(state.messages[-1], 'tool_calls') and state.messages[-1].tool_calls else \"synthesize_response\",\n",
    "    {\n",
    "        \"tool_runner\": \"tool_runner\",\n",
    "        \"synthesize_response\": \"synthesize_response\" # LLM이 직접 응답한 경우\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"tool_runner\", \"process_tool_result\")\n",
    "graph.add_edge(\"process_tool_result\", \"synthesize_response\")\n",
    "\n",
    "graph.add_edge(\"synthesize_response\", END)\n",
    "graph.add_edge(\"fallback\", END) # fallback은 이제 직접 END로 갈 수 있음. (synthesize_response로 라우팅하는 대신)\n",
    "\n",
    "final_graph = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c530b90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] 환경 설정을 시작합니다...\n",
      "[2/7] 'data/' 폴더에서 모든 문서를 로드하여 RAG 시스템을 구성합니다...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 .txt files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [01:07<00:37, 12.54s/it]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1400 .pdf files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 .csv files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 105.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 documents from .json files.\n",
      "Total documents loaded: 1431\n",
      "Total chunks created: 2930\n",
      "Initializing Chroma DB...\n",
      "Adding batch 1/23 to Chroma DB...\n",
      "Adding batch 2/23 to Chroma DB...\n",
      "Adding batch 3/23 to Chroma DB...\n",
      "Adding batch 4/23 to Chroma DB...\n",
      "Adding batch 5/23 to Chroma DB...\n",
      "Adding batch 6/23 to Chroma DB...\n",
      "Adding batch 7/23 to Chroma DB...\n",
      "Adding batch 8/23 to Chroma DB...\n",
      "Adding batch 9/23 to Chroma DB...\n",
      "Adding batch 10/23 to Chroma DB...\n",
      "Adding batch 11/23 to Chroma DB...\n",
      "Adding batch 12/23 to Chroma DB...\n",
      "Adding batch 13/23 to Chroma DB...\n",
      "Adding batch 14/23 to Chroma DB...\n",
      "Adding batch 15/23 to Chroma DB...\n",
      "Adding batch 16/23 to Chroma DB...\n",
      "Adding batch 17/23 to Chroma DB...\n",
      "Adding batch 18/23 to Chroma DB...\n",
      "Adding batch 19/23 to Chroma DB...\n",
      "Adding batch 20/23 to Chroma DB...\n",
      "Adding batch 21/23 to Chroma DB...\n",
      "Adding batch 22/23 to Chroma DB...\n",
      "Adding batch 23/23 to Chroma DB...\n",
      "All documents have been added to Chroma DB.\n",
      "[3/7] 평가 데이터셋을 자동으로 생성합니다...\n",
      "Generated 10 Q&A pairs for evaluation.\n",
      "[4/7] 생성된 질문으로 RAG 시스템의 응답을 생성합니다...\n",
      "[5/7] RAGAs 평가를 위한 최종 데이터셋을 구성합니다...\n",
      "[6/7] RAGAs 프레임워크로 시스템 성능 평가를 시작합니다...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02341b055ac4ad58da4b0ba17fc9391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================\n",
      "    RAG 성능 평가 요약 (DataFrame)\n",
      "===================================\n",
      "                      Score\n",
      "Metric                     \n",
      "faithfulness       0.866818\n",
      "answer_relevancy   0.637050\n",
      "context_recall     0.800000\n",
      "context_precision  0.800000\n",
      "\n",
      "========================================\n",
      "     상세 평가 결과 (DataFrame)\n",
      "========================================\n",
      "                                          user_input  \\\n",
      "0                  2024년 12월에 새로 제정된 저작권 관련 법률이 있나요?   \n",
      "1  내가 만든 유튜브 영상이 다른 사람에게 무단으로 도용되었을 때 어떻게 대응할 수 있나요?   \n",
      "2  AI가 합의 없이 젊은 여성의 얼굴을 이용해 포르노 영상을 생성하는 것은 저작권법이...   \n",
      "3  2005년 제정된 Artists’ Rights and Theft Prevention...   \n",
      "4        제가 만든 교육용 영상에 교과서의 삽화 일부를 사용해도 저작권 문제가 없나요?   \n",
      "5       국가나 지방자치단체가 작성한 저작물을 유튜브 영상에 자유롭게 사용할 수 있나요?   \n",
      "6  제가 만든 유튜브 영상에 다른 사람의 음악을 배경음악으로 사용하려면 어떤 권리를 확...   \n",
      "7  제가 오래전에 만든 작품인데, 저작권 보호 기간이 아직 끝나지 않았다면 이 법이 적...   \n",
      "8      웹소설을 원작으로 한 드라마가 저작권 침해가 되려면 어떤 부분이 유사해야 하나요?   \n",
      "9   해외에서 정식으로 구매한 저작권 보호 상품을 국내에서 재판매해도 저작권 침해가 되나요?   \n",
      "\n",
      "                                  retrieved_contexts  \\\n",
      "0  [저작권의 \\n내용\\n2024\\n저작권\\n상담 사례집\\nKOREA COPYRIGHT...   \n",
      "1  [144   1인 미디어 창작자를 위한 저작권 안내서 \\n내 창작물을 무단 도용하는...   \n",
      "2  [18 Copyright and Artificial Intelligence\\n인공지...   \n",
      "3  [works), enacted December 23, 2004.\\n• Fraudul...   \n",
      "4  [QQ\\nAA\\nQQ\\nAA\\n인용하는 정도에 그치거나 표현상의 창작성을 감득(感得...   \n",
      "5  [QQ\\nAA\\n공공저작물의 자유이용 – 제24조의2\\n국가·지방자치단체가 저작재산...   \n",
      "6  [ 창작을 위해 ‘저작물’을 최대한 활용하자    129\\n 창작을 위해 ‘저작...   \n",
      "7  [72   1인 미디어 창작자를 위한 저작권 안내서 \\n옛날 만화 영상(1990 년...   \n",
      "8  [따라서 웹소설과 해당 드라마에 있어 저작권 침해가 인정되기 위해서는 \\n186) ...   \n",
      "9  [나 그 복제물이 해당 저작재산권자의 허락을 받아 판매 등의 방법으로 거래에 제공된...   \n",
      "\n",
      "                                            response  \\\n",
      "0                                  관련 정보를 찾을 수 없습니다.   \n",
      "1  내가 만든 유튜브 영상이 다른 사람에게 무단으로 도용되었을 때는 다음과 같은 단계로...   \n",
      "2  AI가 합의 없이 젊은 여성의 얼굴을 이용해 포르노 영상을 생성하는 행위는 저작권법...   \n",
      "3  2005년에 제정된 Artists’ Rights and Theft Preventio...   \n",
      "4  교육용 영상에 교과서의 삽화 일부를 사용하는 경우에도 저작권 문제가 발생할 수 있습...   \n",
      "5  국가나 지방자치단체가 저작재산권을 전부 보유하고 있는 공표된 저작물은 누구나 자유롭...   \n",
      "6  유튜브 영상에 다른 사람의 음악을 배경음악으로 사용하려면 다음과 같은 권리를 확인하...   \n",
      "7  네, 저작권 보호기간이 아직 끝나지 않은 작품이라면 저작권법이 적용됩니다. 저작권 ...   \n",
      "8  웹소설을 원작으로 한 드라마에서 저작권 침해가 인정되기 위해서는 단순히 전형적인 주...   \n",
      "9  해외에서 정식으로 구매한 저작권 보호 상품을 국내에서 재판매하는 경우, 우리나라에서...   \n",
      "\n",
      "                                           reference  faithfulness  \\\n",
      "0  2024년 12월에는 Servicemember Quality of Life Impr...      1.000000   \n",
      "1  무단 도용이 확인되면 우선 플랫폼 사업자에게 게시 중단 요청을 하여 확산을 막을 수...      1.000000   \n",
      "2  AI가 합의 없이 젊은 여성의 얼굴을 이용해 포르노 영상을 생성하는 것은 초상권 침...      0.800000   \n",
      "3  2005년에 제정된 Artists’ Rights and Theft Preventio...      1.000000   \n",
      "4  교과서의 삽화는 출판을 위해 준비된 문학적, 그림적 또는 그래픽 작품으로서 체계적인...      0.818182   \n",
      "5  국가 또는 지방자치단체가 업무상 작성하여 공표한 저작물이나 계약에 따라 저작재산권 ...      0.500000   \n",
      "6  다른 사람의 음악을 영상에 사용하려면 저작권뿐만 아니라 저작인접권도 확인해야 하며,...      0.875000   \n",
      "7  이 법은 발효 이전에 만들어진 작품이라도 보호 기간이 아직 만료되지 않았다면 적용됩니다.      0.875000   \n",
      "8  웹소설과 드라마 사이에 저작권 침해가 인정되기 위해서는 추상적인 인물 유형이나 전형...      1.000000   \n",
      "9  해외에서 적법하게 제작·판매된 저작권 보호 상품을 국내에서 재판매하는 경우, 우리나...      0.800000   \n",
      "\n",
      "   answer_relevancy  context_recall  context_precision  \n",
      "0          0.000000             0.0                0.0  \n",
      "1          0.722676             1.0                1.0  \n",
      "2          0.748637             1.0                1.0  \n",
      "3          0.825668             1.0                1.0  \n",
      "4          0.702687             0.0                0.0  \n",
      "5          0.690474             1.0                1.0  \n",
      "6          0.687732             1.0                1.0  \n",
      "7          0.581208             1.0                1.0  \n",
      "8          0.692578             1.0                1.0  \n",
      "9          0.718837             1.0                1.0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np  # numpy 임포트\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader, CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    AnswerRelevancy,\n",
    "    ContextRecall,\n",
    "    ContextPrecision,\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from datasets import Dataset\n",
    "\n",
    "# --- 1. 환경 설정 ---\n",
    "print(\"[1/7] 환경 설정을 시작합니다...\")\n",
    "load_dotenv()\n",
    "\n",
    "EVAL_LLM = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "EVAL_EMBEDDING_MODEL = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "KNOWLEDGE_BASE_FOLDER_PATH = \"data/\"\n",
    "NUM_EVAL_SAMPLES = 10\n",
    "CHROMA_PERSIST_DIRECTORY = \"vector_store/chroma/copyright_law\"\n",
    "CHROMA_COLLECTION_NAME = \"copyright_law_rag\"\n",
    "\n",
    "# --- 2. 문서 로드 및 RAG 체인 구성 ---\n",
    "print(f\"[2/7] '{KNOWLEDGE_BASE_FOLDER_PATH}' 폴더에서 모든 문서를 로드하여 RAG 시스템을 구성합니다...\")\n",
    "\n",
    "txt_loader = DirectoryLoader(KNOWLEDGE_BASE_FOLDER_PATH, glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True)\n",
    "txt_docs = txt_loader.load()\n",
    "print(f\"Found {len(txt_docs)} .txt files.\")\n",
    "\n",
    "pdf_loader = DirectoryLoader(KNOWLEDGE_BASE_FOLDER_PATH, glob=\"**/*.pdf\", loader_cls=PyPDFLoader, show_progress=True)\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f\"Found {len(pdf_docs)} .pdf files.\")\n",
    "\n",
    "csv_loader = DirectoryLoader(KNOWLEDGE_BASE_FOLDER_PATH, glob=\"**/*.csv\", loader_cls=CSVLoader, loader_kwargs={'encoding': 'utf-8', 'source_column': 'contents'}, show_progress=True)\n",
    "csv_docs = csv_loader.load()\n",
    "print(f\"Found {len(csv_docs)} .csv files.\")\n",
    "\n",
    "json_loader = DirectoryLoader(KNOWLEDGE_BASE_FOLDER_PATH, glob=\"**/*.json\", loader_cls=JSONLoader, loader_kwargs={'jq_schema': '.[] | .content', 'text_content': False}, show_progress=True)\n",
    "json_docs = json_loader.load()\n",
    "print(f\"Found {len(json_docs)} documents from .json files.\")\n",
    "\n",
    "all_docs = txt_docs + pdf_docs + csv_docs + json_docs\n",
    "print(f\"Total documents loaded: {len(all_docs)}\")\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = splitter.split_documents(all_docs)\n",
    "print(f\"Total chunks created: {len(split_docs)}\")\n",
    "\n",
    "print(\"Initializing Chroma DB...\")\n",
    "vector_store = Chroma(embedding_function=EVAL_EMBEDDING_MODEL, collection_name=CHROMA_COLLECTION_NAME, persist_directory=CHROMA_PERSIST_DIRECTORY)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "num_batches = (len(split_docs) - 1) // BATCH_SIZE + 1\n",
    "for i in range(num_batches):\n",
    "    start_index = i * BATCH_SIZE\n",
    "    end_index = start_index + BATCH_SIZE\n",
    "    batch_docs = split_docs[start_index:end_index]\n",
    "    print(f\"Adding batch {i+1}/{num_batches} to Chroma DB...\")\n",
    "    vector_store.add_documents(batch_docs)\n",
    "\n",
    "print(\"All documents have been added to Chroma DB.\")\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "#Instruction:\n",
    "당신은 전문가입니다. 주어진 Context 내용을 바탕으로 질문에 대해 정확하고 근거에 기반하여 답변하세요.\n",
    "Context에 질문과 관련된 내용이 없으면 \"관련 정보를 찾을 수 없습니다.\"라고 답변하세요.\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#질문:\n",
    "{query}\n",
    "\"\"\"\n",
    "rag_prompt = PromptTemplate.from_template(RAG_PROMPT_TEMPLATE)\n",
    "\n",
    "rag_chain_for_eval = (\n",
    "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"context\": \"\\n\\n\".join([doc.page_content for doc in x[\"context\"]]),\n",
    "        \"query\": x[\"query\"],\n",
    "        \"contexts\": [doc.page_content for doc in x[\"context\"]]\n",
    "    })\n",
    "    | {\n",
    "        \"answer\": rag_prompt | EVAL_LLM | StrOutputParser(),\n",
    "        \"contexts\": lambda x: x[\"contexts\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- 3. 평가 데이터셋 자동 생성 ---\n",
    "print(\"[3/7] 평가 데이터셋을 자동으로 생성합니다...\")\n",
    "\n",
    "class QASchema(BaseModel):\n",
    "    question: str = Field(description=\"주어진 문맥을 바탕으로 생성된 사용자 질문\")\n",
    "    ground_truth: str = Field(description=\"생성된 질문에 대한, 문맥에 충실한 정답\")\n",
    "\n",
    "QA_GEN_PROMPT = \"\"\"\n",
    "#Instruction:\n",
    "당신은 '크리에이터를 위한 저작권법 RAG 챗봇'의 성능을 평가할 데이터셋을 만드는 AI입니다.\n",
    "당신의 임무는 유튜버, 블로거, 웹툰 작가, 디자이너 등 콘텐츠 크리에이터의 관점에서 질문과 정답 쌍을 생성하는 것입니다.\n",
    "생성할 질문은 크리에이터들이 자신의 창작 활동(예: 영상 제작, 굿즈 판매, 폰트 사용, 2차 창작) 중에 마주칠 수 있는\n",
    "구체적이고 현실적인 저작권법 관련 궁금증이어야 합니다.\n",
    "- 질문과 정답은 반드시 주어진 [Context]에 있는 정보만을 근거로 생성해야 합니다.\n",
    "- 정답은 [Context]를 바탕으로 질문에 대해 완전한 문장으로 작성해주세요.\n",
    "- \"문서에 따르면\", \"제공된 내용에 의하면\" 과 같은 표현은 질문에 포함하지 마세요.\n",
    "\n",
    "# 좋은 질문 예시:\n",
    "- \"제가 만든 유튜브 영상에 다른 사람의 음악 5초 정도를 배경음악으로 써도 저작권에 걸리나요?\"\n",
    "- \"인터넷에서 본 폰트를 제 상업용 굿즈에 사용해도 되나요?\"\n",
    "- \"다른 사람의 글을 리뷰하면서 일부 인용하는 건 어디까지 허용되나요?\"\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#Output Indicator:\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "parser = JsonOutputParser(pydantic_object=QASchema)\n",
    "qa_gen_prompt = PromptTemplate(\n",
    "    template=QA_GEN_PROMPT,\n",
    "    input_variables=[\"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "qa_gen_chain = qa_gen_prompt | EVAL_LLM | parser\n",
    "\n",
    "random.shuffle(split_docs)\n",
    "selected_docs_for_qa = split_docs[:min(NUM_EVAL_SAMPLES, len(split_docs))]\n",
    "eval_data_list = qa_gen_chain.batch([{\"context\": doc.page_content} for doc in selected_docs_for_qa])\n",
    "print(f\"Generated {len(eval_data_list)} Q&A pairs for evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b680d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. RAG 시스템 응답 생성 ---\n",
    "print(\"[4/7] 생성된 질문으로 RAG 시스템의 응답을 생성합니다...\")\n",
    "questions = [item['question'] for item in eval_data_list]\n",
    "rag_responses = rag_chain_for_eval.batch(questions)\n",
    "\n",
    "# --- 5. RAGAs 평가 데이터셋 구성 ---\n",
    "print(\"[5/7] RAGAs 평가를 위한 최종 데이터셋을 구성합니다...\")\n",
    "data_for_ragas = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": [resp['answer'] for resp in rag_responses],\n",
    "    \"contexts\": [resp['contexts'] for resp in rag_responses],\n",
    "    \"ground_truth\": [item['ground_truth'] for item in eval_data_list]\n",
    "}\n",
    "ragas_dataset = Dataset.from_dict(data_for_ragas)\n",
    "\n",
    "# --- 6. RAGAs로 성능 평가 실행 ---\n",
    "print(\"[6/7] RAGAs 프레임워크로 시스템 성능 평가를 시작합니다...\")\n",
    "\n",
    "ragas_llm = LangchainLLMWrapper(EVAL_LLM)\n",
    "\n",
    "metrics_to_use = [\n",
    "    Faithfulness(llm=ragas_llm),\n",
    "    AnswerRelevancy(llm=ragas_llm),\n",
    "    ContextRecall(llm=ragas_llm),\n",
    "    ContextPrecision(llm=ragas_llm),\n",
    "]\n",
    "result = evaluate(\n",
    "    dataset=ragas_dataset,\n",
    "    metrics=metrics_to_use,\n",
    "    llm=ragas_llm,\n",
    "    embeddings=EVAL_EMBEDDING_MODEL\n",
    ")\n",
    "\n",
    "# --- 7. 최종 결과 출력 (수정된 부분) ---\n",
    "\n",
    "# 각 평가지표는 점수 리스트를 반환하므로, 평균(mean)을 계산하여 요약 점수를 만듭니다.\n",
    "summary_scores = {\n",
    "    'faithfulness': np.mean(result['faithfulness']),\n",
    "    'answer_relevancy': np.mean(result['answer_relevancy']),\n",
    "    'context_recall': np.mean(result['context_recall']),\n",
    "    'context_precision': np.mean(result['context_precision']),\n",
    "}\n",
    "df_summary = pd.DataFrame.from_dict(summary_scores, orient='index', columns=['Score'])\n",
    "df_summary.index.name = 'Metric'\n",
    "\n",
    "# 상세 결과는 to_pandas()를 사용하여 각 샘플별 점수를 확인합니다.\n",
    "df_detailed_result = result.to_pandas()\n",
    "\n",
    "# --- 최종 결과 출력 ---\n",
    "print(\"\\n\" + \"=\"*35)\n",
    "print(\"    RAG 성능 평가 요약 (DataFrame)\")\n",
    "print(\"=\"*35)\n",
    "print(df_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"     상세 평가 결과 (DataFrame)\")\n",
    "print(\"=\"*40)\n",
    "print(df_detailed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd2c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2bcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3711fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c57c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77d3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8861ff18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
